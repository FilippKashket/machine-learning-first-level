{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tanKek3DRgOj"
   },
   "source": [
    "# Урок 2. Stacking.\n",
    "\n",
    "Теперь поговорим о стекинге - другом популярном способе ансамблирования алгоритмов. Он принципиально отличается от бустинга двумя положениями. Первое, в стекинге обычно используются разнородные базовые алгоритмы (например, kNN, метод опорных векторов и дерево решений), тогда как в бустинге обычно используют ансамбли однородных алгоритмов (обычно применяются деревья решений). Второе, стекинг объединяет базовые алгоритмы, используя мета-алгоритм, который самостоятельно обучается на предоставленных базовыми моделями данных. Бустинг в свою очередь объединяет их, следуя детерминированному алгоритму."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uBXdr151RgOk"
   },
   "source": [
    "Идея стекинга лежит на поверхности. Известно, что, если обучить несколько разных алгоритмов, то в задаче регрессии их среднее, а в задаче классификации — голосование по большинству, часто превосходят по качеству все эти алгоритмы по отдельности. Возникает вопрос: почему, собственно, нужно использовать для ансамблирования такие операции как усреднение или голосование? Можно же доверить ансамблироование очередному алгоритму (т.н. мета-алгоритму) машинного обучения, чтобы он сам решил, как ему действовать с полученными ответами базовых алгоритмов.\n",
    "\n",
    "Чтобы понять, как работает классический стекинг, сначала разберем его простейшую реализацию - **блендинг (blending)**. Обучающую выборку делят на две части. \n",
    "\n",
    "![](https://248006.selcdn.ru/public/DS.%20Block%202.%20M9/blending_1.png)\n",
    "\n",
    "На первой обучают базовые алгоритмы. Затем получают их ответы на второй части и на тестовой выборке. \n",
    "\n",
    "![](https://248006.selcdn.ru/public/DS.%20Block%202.%20M9/blending_2.png)\n",
    "\n",
    "Понятно, что  ответ каждого алгоритма можно рассматривать как новый признак (т.н. метапризнак). На метапризнаках второй части обучения настраивают метаалгоритм. Затем запускают его на метапризнаках теста и получают ответ.\n",
    "\n",
    "![](https://248006.selcdn.ru/public/DS.%20Block%202.%20M9/blending_3.png)\n",
    "\n",
    "В такой реализации самый большой недостаток - деление обучающей выборки. Получается, что ни базовые алгоритмы, ни метаалгоритм не используют всего объёма обучения, а значит, мы можем пропустить важные данные.\n",
    "\n",
    "Один из способов борьбы за использование всей обучающей выборки - реализация классического **стекинга (stacking)**. Понятно, что обучить базовые алгоритмы на всей обучающей выборке и потом для той же выборки построить метапризнаки нельзя: будет очевидное переобучение. Поэтому выборку разбивают на части (т.н. фолды, как в кросс-валидации).\n",
    "\n",
    "![](https://248006.selcdn.ru/public/DS.%20Block%202.%20M9/meta_1.png)\n",
    "\n",
    "Затем последовательно для каждого обучают базовые алгоритмы на всех фолдах, кроме одного, а на оставшемся получают ответы базовых алгоритмов и трактуют их как значения соответствующих метапризнаков на этом фолде.\n",
    "\n",
    "![](https://248006.selcdn.ru/public/DS.%20Block%202.%20M9/meta_2.png)\n",
    "\n",
    "Для получения метапризнаков объектов тестовой выборки базовые алгоритмы обучают на всей тренировочной выборке и берут их ответы на тестовой.\n",
    "\n",
    "![](https://248006.selcdn.ru/public/DS.%20Block%202.%20M9/meta_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pfOCrGvNRgOk"
   },
   "source": [
    "Для примера, если взять M базовых алгоритмов и обучить их на N объектах, то окончательная матрица метапризнаков для обучения мета-алгоритма будет выглядеть так:\n",
    "![](https://248006.selcdn.ru/public/DS.%20Block%202.%20M9/meta_mtrx.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "27CtAuBSRgOl"
   },
   "source": [
    "Отметим, что стекинг не всегда существенно повышает качество лучшего из базовых алгоритмов, однако если этот алгоритм убрать из базовых, то и качество стекинга не сильно падает.\n",
    "\n",
    "Также возможно использовать стекинг с несколькими слоями, т.н. многоуровневый стекинг, т.е. ввести понятие мета-мета признака и мета-мета алгоритма и далее при желании расширить еще на несколько слоев. Такой метод часто применяется в соревнованиях по машинному обучению, где борьба идет за десятитысячные доли к точности модели, однако саму модель это сделает неинтерпретируемой, что плохо для бизнес-задач."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iXKnTgSGRgOm"
   },
   "source": [
    "Вообще, в sklearn нет реализации стекинга, но существуют такие небазовые пакеты python как mlxtend или vecstack, в которых присутствует этот метод, которым можно воспользоваться \"из коробки\".\n",
    "\n",
    "Мы же на примере базовой реализации блендинга покажем, как работает этот метод. В качестве базовых алгоритмов возьмем kNN, LogisticRegression, DesisionTreeClassifier и SupportVectorClassification, а в качестве мета-алгоритма будем использовать XGBoost.\n",
    "\n",
    "Будем проверять работу стекинга на том же преобразованном датасете Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Y31RssbRgOm"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dr-cJfq4RgOp"
   },
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('titanic.csv')\n",
    "targets = titanic.Survived\n",
    "data = titanic.drop(columns='Survived')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, \n",
    "                                                    targets,\n",
    "                                                    train_size=0.8,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CDwyxGm4RgOr"
   },
   "source": [
    "Так как нам нужно и обучить базовые алгоритмы на тренировочном сете, и сделать на этих же данных предсказания для обучения мета-алгоритма, разделим тренировочные данные еще на два датасета: train и valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "URlop4hfRgOs"
   },
   "outputs": [],
   "source": [
    "train, valid, train_true, valid_true = train_test_split(x_train, \n",
    "                                                        y_train,\n",
    "                                                        train_size=0.5,\n",
    "                                                        random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "42swuKzARgOw"
   },
   "source": [
    "Обучим базовые алгоритмы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yUyHZcPORgOz",
    "outputId": "e827376a-024d-4354-cf4a-f479504b04c2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/impuling/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/impuling/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/impuling/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_model = knn.fit(train, train_true)\n",
    "\n",
    "lr = LogisticRegression(random_state=17)\n",
    "lr_model = lr.fit(train, train_true)\n",
    "\n",
    "dtc = DecisionTreeClassifier(max_leaf_nodes=4, random_state=17)\n",
    "dtc_model = lr.fit(train, train_true)\n",
    "\n",
    "svc = SVC(random_state=17)\n",
    "svc_model = svc.fit(train, train_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DKitWP9SRgO3"
   },
   "source": [
    "Теперь получим предсказания моделей для второй части тренировочных данных - valid, заполним получившимися метапризнаками матрицу для обучения мета-алгоритма и обучим его.\n",
    "\n",
    "Заодно получим для каждого базового алгоритма метрику AUC для тестовых данных, которая покажет качество работы каждого алгоритма в отдельности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KkVIP_VURgO4",
    "outputId": "de61f589-4752-47fd-db6f-1222ed5e9f53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 auc: 0.7080368906455863\n",
      "1 auc: 0.7777997364953887\n",
      "2 auc: 0.7777997364953887\n",
      "3 auc: 0.620223978919631\n"
     ]
    }
   ],
   "source": [
    "models = [knn_model, lr_model, dtc_model, svc_model]\n",
    "meta_mtrx = np.empty((valid.shape[0], len(models))) # (кол-во объектов, 4 алгоритма)\n",
    "\n",
    "for n, model in enumerate(models):\n",
    "    meta_mtrx[:, n] = model.predict(valid)\n",
    "    predicted = model.predict(x_test)\n",
    "    print(f'{n} auc: {roc_auc_score(y_test, predicted)}')\n",
    "    \n",
    "meta = XGBClassifier(n_estimators=40)\n",
    "meta_model = meta.fit(meta_mtrx, valid_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EikSGE2IRgO6"
   },
   "source": [
    "Получим метапризнаки базовых алгоритмов для тестовых данных, чтобы мета-алгоритм мог по ним сделать предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sqzA76RpRgO6",
    "outputId": "cffa132b-6637-4dcb-bd6b-ba45545cdf81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking AUC: 0.7777997364953887\n"
     ]
    }
   ],
   "source": [
    "meta_mtrx_test = np.empty((x_test.shape[0], len(models))) \n",
    "\n",
    "for n, model in enumerate(models):\n",
    "    meta_mtrx_test[:, n] = model.predict(x_test)\n",
    "    \n",
    "meta_predict = meta.predict(meta_mtrx_test)\n",
    "print(f'Stacking AUC: {roc_auc_score(y_test, meta_predict)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PoVmoAGfRgO8"
   },
   "source": [
    "Как мы видим, в этом случае финальный скор AUC не превышает результат лучших базовых алгоритмов. Попробуем убрать базовые алгоритмы с лучшими результатами и посмотреть, что изменится."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eOYjMlVtRgO9",
    "outputId": "78fe0d21-ffbf-44d0-a2d5-d1ea6e8f2071"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 auc: 0.7080368906455863\n",
      "1 auc: 0.620223978919631\n",
      "Stacking AUC: 0.7233860342555994\n"
     ]
    }
   ],
   "source": [
    "models = [knn_model, svc_model]\n",
    "meta_mtrx = np.empty((valid.shape[0], len(models))) # (кол-во объектов, 4 алгоритма)\n",
    "\n",
    "for n, model in enumerate(models):\n",
    "    meta_mtrx[:, n] = model.predict(valid)\n",
    "    predicted = model.predict(x_test)\n",
    "    print(f'{n} auc: {roc_auc_score(y_test, predicted)}')\n",
    "\n",
    "meta_model = meta.fit(meta_mtrx, valid_true)\n",
    "\n",
    "meta_mtrx_test = np.empty((x_test.shape[0], len(models))) \n",
    "\n",
    "for n, model in enumerate(models):\n",
    "    meta_mtrx_test[:, n] = model.predict(x_test)\n",
    "    \n",
    "meta_predict = meta.predict(meta_mtrx_test)\n",
    "print(f'Stacking AUC: {roc_auc_score(y_test, meta_predict)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tA1ImyyZRgPB"
   },
   "source": [
    "Здесь же видно, что стекинг двух не самых лучших базовых алгоритмов дает результат выше, чем у каждого из них по отдельности."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "jun_ml_extra_tech_stack.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
