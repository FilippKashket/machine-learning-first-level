{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uKJGB4sCiWzr"
   },
   "source": [
    "В прошлом уроке мы узнали, как обучить и применить модель линейной регрессии, а так же как измерить качество модели. В этом уроке поговорим, как улучшить этот простой алгоритм и сделать обучение более эффективным. Мы познакомимся с понятиями \"регуляризация\" и \"градиентный спуск\".\n",
    "\n",
    "Вы сможете обучать линейную регрессию, не \"упираясь\" в аппаратные ресурсы, а так же узнаете, как увеличить качество решения с помощью механизма регуляризации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WjRhay_4iWzs"
   },
   "source": [
    "# Урок 1. Регуляризация\n",
    "\n",
    "Регуляризация - это способ борьбы с таким явлением как \"переобучение\".\n",
    "\n",
    "**Что такое переобучение?** Переобучение (англ. *overfitting*, буквально - \"переподгонка\") - негативное явление, возникающее, когда алгоритм обучения вырабатывает предсказания, которые слишком близко или точно соответствуют конкретному набору данных и поэтому не подходят для применения алгоритма к дополнительным данным или будущим наблюдениям."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8qvDUDUQiWzt"
   },
   "source": [
    "Пример оверфиттинга проще всего привести в виде картинки. Пусть вы решаете задачу классификации на два класса ( о которой уже знаете с первых уроков этого курса)\n",
    "* сначала модель, которая обучена не совсем хорошо (underfit) - разделяющая линия прямая и много \"красных\" точек неправильно классифицированы\n",
    "* затем хорошо обученная модель (normal) - есть какой-то баланс\n",
    "* переобученная модель (overfit) - разделяющая линия слишком сильно \"облизывает\" обучающие данные.\n",
    " \n",
    "![overfit_example](https://248006.selcdn.ru/public/Data-science-3/img/overfit_example.png)\n",
    "\n",
    "Чем же плохо переобучение? Когда в модель придут \"новые\" точки то качество модели будет низким, потому что модель слишком сильно подогналась под обучающие данные. В этом случае говорят, что падает \"обобщающая способность\" - модель не получается обощить на новые данные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qA8rAxXCiWzu"
   },
   "source": [
    "**Почему происходит переобучение?** Всё дело в алгоритме подбора параметров модели. В модуле \"Линейная регрессия. Часть I\" в домашнем задании по уроку \"Полиномиальная регрессия\" нужно было побобрать такой параметр, как \"степень полинома\". Напомним общий алгоритм выбора *наилучшей степени полинома*:\n",
    "\n",
    "\n",
    "1. возьмите все степени от 1 до 10 по порядку, без пропусков\n",
    "1. Для каждой степени полинома: обучите полиномиальную регрессию, сделайте предсказания и вычислите метрику качества (например, r2-score)\n",
    "1. найдите степень полинома, при которой у модели будет лучший r2-score\n",
    "\n",
    "Вспомним, что эта процедура называется *Grid Search* и помогает найти лучшие параметры для модели методом перебора.\n",
    "\n",
    "Вот тут-то и поджидает нас переобучение! Мы выберем модель, которая даёт лучший скор на обучающих данных. А вот когда в модель придут новые данные то качество может быть сильно хуже"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fpCOgxlFiWzu"
   },
   "source": [
    "**Как детектировать переобучение?** Перед нами стоит вопрос, как выбрать правильные пераметры модели, чтобы она не \"оверфитнулась\". Есть простой алгоритм, который называется \"контроль на отложенной (валидационной) выборке\". Тренировку модели из пункта (2) алгоритма *GridSearch* придётся немного усложнить:\n",
    "\n",
    "* разбиваем обучающую выборку на две части: в одной части 80% обучающих примеров (эта часть называется *train set*), в другой части 20% обучающих примеров (эта часть называется *validation set*)\n",
    "* выбираем метрику качества  модели (для регрессии, например, RMSE)\n",
    "* обучаем модель на тренировочном наборе данных.\n",
    "* делаем предсказания на валидационном наборе данных и вычисляем метрику качества\n",
    "\n",
    "**Признак переобучения**: Если качество на валидации сильно хуже, чем качество на обучающем сете - всё плохо, модель переобучилась. Запомните этот признак, скоро мы его применим на практике. Такую модель нельзя использовать, с переобучением надо бороться!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w_J31zceiWzv"
   },
   "source": [
    "**Как бороться с переобучением линейной регрессии?** Нам надо как-то \"наказать\" модель за то, что она слишком сильно подгоняется под обучающую выборку. Это можно сделать помощью регуляризации! Регуляризация - это специальная модификация модели линейной регрессии. В стандартной библиотеки sklearn есть два класса, в которых реализована регуляризация:\n",
    "* sklearn.linear_model.Ridge, ссылка на доку https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html\n",
    "* sklearn.linear_model.Lasso, ссылка на доку https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\n",
    "\n",
    "Чем отличаются эти два класса мы узнаем в следующих уроках этого модуля. Мы уже знакомы с классом `sklearn.linear_model.LinearRegression`, с который вообще не требует никаких параметров при создании, а вот классы `Ridge` и `Lasso` принимают на вход т.н. параметр регуляризации *alpha*, который принимает значения от $0$ до $1$ - чем ближе к единице, тем регуляризация сильнее, тем сильнее наказываем модель за сильную \"подгонку\" под обучающие данные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dxd8yfwFiWzw"
   },
   "source": [
    "В следующем уроке мы  продемонстрируем, как переобучается полиномиальная регрессия, а так же попытаемся победить этот эффект с помощью регуляризации"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "name": "jun_ml_linear_regression_II_les_1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
