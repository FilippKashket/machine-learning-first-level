{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Урок 3. Метрики качества линейной регрессии\n",
    "\n",
    "В задачах машинного обучения мы хотим сравнивать несколько моделей машинного обучения и выбирать наилучшую из них. Решение о том, какая модель хорошая, а какая плохая, принимается на основе одной или нескольких *метрик* моделей машинного обучения.\n",
    "\n",
    "Без метрик обучение моделей вообще теряет всякий смысл - как же определить, какая из зоопарка обученных моделек хорошая, а какая плохая? Давайте разберёмся, как определить лучшую модель с помощую математики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте вернёмся к картинке из первого урока. От каждой красной точки до синей линии отложены отрезки, которые представляют собой ошибку регрессии - как сильно модель ошибается на каждой из точек.\n",
    "\n",
    "![least_squares_learning](https://248006.selcdn.ru/public/Data-science-4/img/least_line.png)\n",
    "\n",
    "Интуиция за метриками стоит оцень простая - давайте как-нибудь усредним отклонения по всем точкам и получим одно число - метрику качества линейной регрессии, т.е. насколько модель отклоняется от реальных данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрики принимают на вход два вектора - предсказания модели и истинные значения, после чего вычисляют по этим векторам качество модели.\n",
    "\n",
    "Сначала загрузим данные эксперимента - датасет с ценами на дома в Бостоне"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston_dataset = load_boston()\n",
    "\n",
    "features = boston_dataset.data\n",
    "y = boston_dataset.target\n",
    "\n",
    "reg = LinearRegression().fit(features, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь получим два вектора - предказанное значение $\\hat{y}$ и  истинное значение $y$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(features) # предсказанное значение\n",
    "y_true = y # истинное значение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь посмотрим, какие функции можно применять к этим двум наборам точек"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean absolute error\n",
    "\n",
    "Для оценки качества регрессии можно использовать среднюю абсолютную ошибку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 3.270862810900316\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "print(\"MAE = %s\" % mean_absolute_error(\n",
    "    reg.predict(features), y)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Mean Absolute Error* - это просто сумма отклонений истинных значений $y$ от предсказаний нашей модели:\n",
    "\n",
    "$$\n",
    "\\text{absolute error} = |y_1 - \\hat{y}_1| + |y_2 - \\hat{y}_2| + \\ldots\n",
    "$$\n",
    "\n",
    "А потом мы эту сумму делим на количество точек - получаем среднюю ошибку\n",
    "\n",
    "Метрика принимает только положительные значения! Чем ближе к нулю, тем лучше модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE\n",
    "\n",
    "Root Mean Square Error (RMSE) - это базовая метрика для определения качества линейной регрессии\n",
    "\n",
    "Для каждого предсказанного значения $\\hat{y}_i$ мы считаем квадрат отклонения от фактического значения и считаем среднее по полученным величинам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 21.894831181729202\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "print('RMSE = %s' % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом логика та же, что в *MAE*, только усреднять мы будем квадраты ошибок \n",
    "$$\n",
    "\\text{absolute error} = (y_1 - \\hat{y}_1)^2 + (y_2 - \\hat{y}_2)^2 + \\ldots\n",
    "$$\n",
    "\n",
    "Эта метрика тоже принимает только положительные значения! Чем ближе к нулю, тем лучше модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта ошибка визуально похожа на  *RMSE*, но На графике видно, что *MAE*(красная линия) почти всегда меньше по значению, чем RMSE (синяя линия). Это значит, что *RMSE* более \"пессимистична\" и сильнее штрафует за большие ошибки - т.е. RMSE лучше применять, когда вы уверены что в выборке нет \"выборосов\" (англ. outliers) - значений, который очень сильно отличаются от остальных точек. В этом случае RMSE может быть очень похой, а на деле ситуация приемлема. Если выбросы есть, лучше применять MAE.\n",
    "\n",
    "![rmse_vs_mae](https://248006.selcdn.ru/public/Data-science-4/img/rmse_vs_mae.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнение *RMSE* и *MAE* на табличных данных\n",
    "\n",
    "* все ошибки одинаковые - RMSE и MAE совпали\n",
    "* ошибки с небольшой дисперсией - RMSE увеличивается\n",
    "* 9 примеров угадали точно, один с большой ошибкой (потому что аутлаер) - *RMSE* огромный\n",
    "\n",
    "хотя *MAE* в трёх примерах одинаковый, а вот *RMSE* совсем разный"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![metrics](https://248006.selcdn.ru/public/Data-science-4/img/metrics.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $R^2$ (коэффициент детерминации)\n",
    "\n",
    "Название - калька английского термина *coefficient of determination*. Наилучшее возможное значение 1.0, чем меньше тем хуже. Если этот коэффициент близок к 1, то условная дисперсия модели (то есть разброс предсказаний модели $\\hat{y}$ относительно разброса самой целевой переменной $y$ ) достаточно мала - то есть модель неплохо описывает данные. Коэффициент может быть даже отрицательным - то это значит, что модель совсем уж плохая.\n",
    "\n",
    "Эта метрика хороша тем, что она *нормализована*, то есть не превышает единицу - удобно сравнивать разные модели. Например, метрика $RMSE$ может принимать ничем не ограниченные значения больше нуля - это не всегда удобно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В библиотеке *sklearn* есть готовая реализация этой метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score = 0.7406426641094095\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print(\"r2_score = %s\" % r2_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Про другие ошибки можно почитать в [официальной документации](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics) в разделе про метрики регрессии."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
