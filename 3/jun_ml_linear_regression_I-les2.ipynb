{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ka-1t_7gzLxa"
   },
   "source": [
    "# Урок 2. Продвинутый уровень понимания линейной регрессии\n",
    "\n",
    "\n",
    "Как понять, насколько хорошо наша модель \"выучилась\" по данным - насколько хорошо она попала в центр облака точек? Давайте введём какую-то меру качества модели - тогда мы сможем говорить, что модель обучается, когда растёт мера качества ( о метриках качества мы поговорим в следующем урове этого модуля), Процесс машинного обучения сводится к тому, чтобы по опыту (обучающей выборке) $D$ подобрать такие коэффициенты линейной регрессии, что мера качества $L$ будет максимальной. Хорошей мерой качества $L$ для задачи регрессии является среднее значение квадрата разности между фактическим значением $y$ и прогнозом $\\hat{y}$ - такая метрика называется *Mean Square Error* (берём со знаком минус, т.к. при увеличении качества модели метрика должна расти).\n",
    "$$\n",
    "L(\\hat{y}, y) = -\\frac{1}{N}\\sum_{i=1}^{N}\\left(y_i - \\hat{y_i}\\right)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kcmIQIPbzLxc"
   },
   "source": [
    "Линейная регрессия относится в задачам обучения с учителем: опыт $D$ (который в ML называют *обучающей выборкой*) в нашем случае - это набор пар $x_i, y_i$ таких, что\n",
    "\n",
    "$$\n",
    "D = \\{(x_i, y_i) \\}_{i=\\overline{1,N}}\n",
    "$$\n",
    "\n",
    "Где $y_i$ - это \"правильный\" ответ (значение переменной $y$) на обучающем примере $x_i$, а $N$ - количество обучающих примеров. В задаче линейной регрессии $y \\in R$, то есть предсказывать нужно  непрерывную величину (в отличие от задачи глассификации, где предсказания должны быть дискретными)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yDw5FZA8zLxd"
   },
   "source": [
    "Каждый объект $x_i$ является совокупностью признаков $x_i^1,\\ldots, x_i^k$. Размерность признакового пространства может быть разной, т.е. $x_i \\in R^k$, где $k$ может принимать значения от 1 (в задаче прогнозирования роста человека по его весу) до десятков тысяч (например, в задаче анализа текстов). Вот, например, как выглядит регрессия в трёхмерном пространстве\n",
    "\n",
    "![3d_lin_reg](https://248006.selcdn.ru/public/Data-science-4/img/3d_lin_reg.png)\n",
    "\n",
    "В случае многомерной линейной регрессии для $n-1$ измерений нам нужно будет выучить не два коэффициента $a$ и $b$, а $n$ коэффициентов - по одному на каждую координату $x_i$ плюс один коэффициент-свободный член\n",
    "\n",
    "$$\n",
    "L(\\hat{y}, y) = \\frac{1}{N}\\sum_{i=1}^{N}\\left(y_i - \\hat{y_i}\\right)^2 = \\frac{1}{N}\\sum_{i=1}^{N}\\left(y_i -  \\sum_{j=1}^{n}w_jx_i^j\\right)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2POfYRAWzLxe"
   },
   "source": [
    "В этой формуле:\n",
    "\n",
    "* $N$ - размер обучающей выборки (собрали информацию по 124 домам: $N=124$)\n",
    "* $i$ - порядковый номер объекта из обучающей выборки\n",
    "* $y_i$ - значение целевого признака (например, стоимость дома или рост человека) у объекта под номером $i$\n",
    "* $\\hat{y}_i$ - значение целевого признака, которое предсказала линейная регрессия\n",
    "\n",
    "Дальше мы расписываем, как предсказание $\\hat{y}_i$ получается по фичам:\n",
    "$$\n",
    "\\hat{y}_i = \\sum_{j=1}^{n}w_jx_i^j\n",
    "$$\n",
    "\n",
    "в этой формуле\n",
    "\n",
    "* $n$ - количество фичей (если по площади дома предсказываем цену, то $n=1$, у нас одна фича \n",
    "* $w_j$ - коэффициент при фиче под номером $j$, который показывает силу влияния этой фици на целевую переменную например $w_1$ $=$ `сила влияния площадь дома на его цену`\n",
    "* $x_i^j$ - фича под номером $j$ у объекта под номером $i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l5-TtPRtzLxf"
   },
   "source": [
    "Говоря математическим языком, *задача линейной* регрессии заключается в том, чтобы восстановить функцию зависимости $y$ тот $x$ в виде *линейной комбинации* признаков объекта. Сами признаки называются *фичами* (как и в других задачах машинного обучения):\n",
    "$$\n",
    "\\forall x_i: \\hat{y_i} = w_0 + w_1x_i^1 + \\ldots + + w_nx_i^n = \\sum_{j=1}^{n}w_jx_i^j = \\overline{x}_i^T\\overline{w}\n",
    "$$\n",
    "\n",
    "Если перейти от одного объекта обучающей выборки ко всей выборке с множеством объектом, то формулу **RMSE** удобно для дальнейших вычислений переписать в т.н. матричной форме (подробнее см. в [статье про линейную регрессию](https://ru.wikipedia.org/wiki/Линейная_регрессия) )\n",
    "$$\n",
    "Q_{\\text{emp}} = \\frac{1}{2N}\\sum_{i=1}^{N}(y_i - \\hat{y_i})^2 = \\frac{1}{2N}\\sum_{i=1}^{N}(y_i - \\overline{x}_i^T\\overline{w})^2 = \\frac{1}{2N}||\\overline{Y}-\\overline{X}^T\\overline{w}||^2 = \\frac{1}{2N}\\left(\\overline{Y}-\\overline{X}^T\\overline{w}\\right)^T\\left(\\overline{Y}-\\overline{X}^T\\overline{w}\\right)\n",
    "$$\n",
    "\n",
    "Такой вид функции потерь называется RSS - *resudal squares sum*, на русский переводится как *остаточная сумма квадратов*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1S7sIWCNzLxg"
   },
   "source": [
    "В этой формуле:\n",
    "\n",
    "* $Y$ - вектор-столбец с истинными значениями целевой переменной $y$ размерности $N \\times 1$, где $N$ - размер обучающей выборки\n",
    "* $X$ - матрица с фичами размерости $N \\times n$, где $N$ - размер обучающей выборки, а $n$ - число фичей\n",
    "* $w$ - вектор коэффициентов линейной регрессии размерности $1 \\times n$, где $n$ - количество фичей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j_gs0NPozLxh"
   },
   "source": [
    "Где $\\hat{y_i}$ - ответ нашего алгоритма машинного обучения $h(x, \\theta)$ на примере $x_i$. Чем больше значение $L$ (т.е. чем ближе оно к нулю, т.к. берём со знаком минус) тем лучше наша модель повторяет опыт $X \\in m \\times n$ - матрицу, где m - количество примеров в обучающей выборке, а $m$ - размерность пространства признаков. $w$ - это вектор параметров модели, который хотим обучить.\n",
    "\n",
    "Значение коэффициентов линейной регрессии $w$ которые будут являться решением нашей задачи, можно найти аналитически, он достигается тогда, когда значения коэффициентов равны следующей величине (в матричном виде)\n",
    "$$\n",
    "\\overline{w} = \\left(X^TX\\right)^{-1}X^T\\overline{y}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VgY4jbhPzLxi"
   },
   "source": [
    "Давайте посмотрим, как обучить модель линейной регрессии, пользуясь только библиотечными функциями - имеенно их вы будете применять при решении реальных задач на работе\n",
    "\n",
    "Сначала реализуем вспомогательную функцию для печати чисел  питоновского типа *float* в красивом виде без большого количества знаков после запятой: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6e4LpBl6zLxj"
   },
   "outputs": [],
   "source": [
    "def ndprint(a, format_string ='{0:.2f}'):\n",
    "    \"\"\"Функция, которая распечатывает список в красивом виде\"\"\"\n",
    "    return [format_string.format(v,i) for i,v in enumerate(a)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8DP1fofRzLxo"
   },
   "source": [
    "Загружаем исходные данные - датасет с ценами на дома в Бостоне. Это стандартный датасет, который используется для демонстрации алгоритмов настолько часто, что включён прямо в исходный код библиотеки sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-_fTxmNrzLxp",
    "outputId": "f16bdc68-f90a-47b8-98d7-5e7c7a5d56bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Матрица Объекты X Фичи  (размерность): 506 13\n",
      "\n",
      "Целевая переменная y (размерность): 506\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston_dataset = load_boston()\n",
    "\n",
    "features = boston_dataset.data\n",
    "y = boston_dataset.target\n",
    "\n",
    "print('Матрица Объекты X Фичи  (размерность): %s %s' % features.shape)\n",
    "print('\\nЦелевая переменная y (размерность): %s' % y.shape)\n",
    "\n",
    "\n",
    "# текстовое описание датасета  - распечатать, если интересно print('\\n',boston_dataset.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fGy4qN5xzLxw"
   },
   "source": [
    "Мы будем работать с датасетом в котором 506 наблюдений. У каждого наблюдения 13 фичей. Таким образом наша модель - это вектор $w$ в котором 13 компонент $w_1,\\ldots,w_n$ - по одному коэффициенту на каждую фичу.\n",
    "\n",
    "Код для аналитического вычисления коэффициентов линейной регрессии по формуле $\\overline{w} = \\left(X^TX\\right)^{-1}X^T\\overline{y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vp0ddtAAzLxx",
    "outputId": "d932c0c1-8a8b-44a5-f3d2-e22601dbbeac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Аналитически определённые коэффициенты \n",
      "['-0.09', '0.05', '-0.00', '2.85', '-2.87', '5.93', '-0.01', '-0.97', '0.17', '-0.01', '-0.39', '0.01', '-0.42']\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import inv\n",
    "\n",
    "# вычисляем к-ты линейной регрессии\n",
    "w_analytic = inv(\n",
    "    features.T.dot(features)\n",
    ").dot(\n",
    "    features.T\n",
    ").dot(\n",
    "    y\n",
    ")\n",
    "print(\"Аналитически определённые коэффициенты \\n%s\" % ndprint(w_analytic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QP-WtXKCzLx1"
   },
   "source": [
    "Чтобы проверить, насколько хорошо мы реализовали аналитическое вычисление коэффициентов, воспользуемся готовой библиотечной реализацией. Библиотечная реализация вычисляет коэффициенты не с помощью перемножения матриц (как мы) а с помощью *приближённых* [методов для численного решения](https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.lstsq.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WcI1l7NBzLx2",
    "outputId": "1f3dd4fe-8413-4a0f-d357-c3ecb49dbeb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Коэффициенты, вычисленные моделью sklearn \n",
      "['-0.11', '0.05', '0.02', '2.69', '-17.77', '3.81', '0.00', '-1.48', '0.31', '-0.01', '-0.95', '0.01', '-0.52']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# обучаем модель \"из коробки\"\n",
    "reg = LinearRegression().fit(features, y)\n",
    "print(\"Коэффициенты, вычисленные моделью sklearn \\n%s\" % ndprint(reg.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6pZOnkGUzLyF"
   },
   "source": [
    "Мы реализовали обучение модели линейной регрессии на языке Python, причём полученные коэффициенты в целом совпадают с результатами, полученными с помощью класса `sklearn.linear_model.LinearRegression`, который вычисляет коэффициенты приближённо. На практике пользуются именно библиотечной функцией, потому что при наличии большого количества точке и большого количества фичей \"самописная\" реализация будет работать дольше"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "jun_ml_linear_regression_I-les2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
