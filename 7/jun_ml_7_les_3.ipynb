{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-soeBFwroVLZ"
   },
   "source": [
    "# Урок 3. Выбор количества кластеров $k$ в алгоритме *k-means*\n",
    "\n",
    "Существенный недостаток алгоритма заключается в необходимости до начала эксперимента выбирать количество кластеров. В этом уроке мы научимся выбирать количество кластеров $K$ автоматически.\n",
    "\n",
    "Мы будем подходить к выбору оптимального количества кластеров, как к задаче оптимизации - выберем метрику качества кластеризации, которая зависит от параметра $K$ найдём как-нибудь, при каком значении $K$ у нас самая лучшая кластеризация. Хорошей метрикой качества является т.н. внутрикластерное расстояние."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nzPYl34BoVLd"
   },
   "source": [
    "Для подбора вводится метрика качества кластеризации с центроидами $\\mu_k: \\forall k=1,\\ldots,K$, которая измеряет внутрикластерное расстояние - насколько хорошо центр, который мы выбрали, совпадает с \"идеальным\" центром кластера\n",
    "$$\n",
    "J(C) = \\sum_{k=1}^{K}\\sum_{j \\in C_k} \\mid x_j - \\mu_k \\mid \\rightarrow min\n",
    "$$\n",
    "\n",
    "В этой формуле\n",
    "* $\\mu_k$ - координаты центроида кластера под номером $k$, количество кластеров $k$\n",
    "* $x_j$ - объект под номером $j$, принадлежащий кластеру под номером $k$\n",
    "* $\\mid x_j - \\mu_k \\mid$ - евклидово расстояние (см. первый урок) от примера $x_j$ до центроида $\\mu_k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YEW0gIBWoVLf"
   },
   "source": [
    "Очевидно, что эта метрика достигает оптимума в точке, где количество соответствует количеству элементов в выборке. Однако, это вырожденный случай - на практике применяют эвристику \"метод локтя\", которая предполагает выбор точки, в которой резко снижается динамика изменения $J(C)$:\n",
    "$$\n",
    "D(K) =\\frac{\\mid J(C_{k+1}) - J(C_{k}) \\mid}{\\mid J(C_{k}) - J(C_{k-1}) \\mid} \\rightarrow \\min\n",
    "$$\n",
    "\n",
    "Пример на картинке:\n",
    "![elbow_method](https://248006.selcdn.ru/public/DS.%20Block%202.%20M7/elbow_method.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5DY-FJYSoVLg"
   },
   "source": [
    "Реализуем алгоритм поиска наилучшего количества кластеров на примере датасета с двумя классами из второго урока"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aSuTbP6toVLi",
    "outputId": "718c3fb4-e7e5-4670-c869-a6c1f664c6bf"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KMeans' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-04a44b9f97f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mMAX_CLUSTERS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcluster_num\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMAX_CLUSTERS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mkmeans_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcluster_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m99\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mcentroids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkmeans_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkmeans_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mmetric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'KMeans' is not defined"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "metrics = []\n",
    "MAX_CLUSTERS = 7\n",
    "for cluster_num in range(1, MAX_CLUSTERS):\n",
    "    kmeans_model = KMeans(n_clusters=cluster_num, random_state=99).fit(X)\n",
    "    centroids, labels = kmeans_model.cluster_centers_, kmeans_model.labels_\n",
    "    metric = 0\n",
    "    for centroid_label in range(cluster_num):\n",
    "        metric += euclidean_distances(\n",
    "            X[labels==centroid_label],\n",
    "            centroids[centroid_label,:].reshape(1,-1)\n",
    "        ).sum(axis=0)[0]\n",
    "    print(\"cluster_num %s, metric %s\" % (cluster_num, metric))\n",
    "    metrics.append(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cg6qx1-RoVLr"
   },
   "source": [
    "Визуализируем зависимость метрики от количества кластеров на графике"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JLXcn23KoVLs",
    "outputId": "4a9502e5-6ac0-49b1-b1dd-26a51e2f3e1e"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-29187b0aeb22>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "D = []\n",
    "for i in range(0, len(metrics)-1):\n",
    "    d = abs(metrics[i+1]-metrics[i])/abs(metrics[i]-metrics[i-1])\n",
    "    D.append(d)\n",
    "print(\"best cluster num: %s\" % (np.argmin(D)+1))\n",
    "\n",
    "plt.plot([i+1 for i in range(len(metrics))], metrics)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oHBK9FZkoVLx"
   },
   "source": [
    "Визуально заметно, что в точке $k=2$ в графике наблюдается перегиб - это и есть тот самый \"локоть\". Значит, оптимальное количество кластеров для нашего датасета $k=2$, что и так было понятно по картинке из первого урока"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R5hytU7VoVLy"
   },
   "source": [
    "В третьем уроке мы научились кластеризовать данные на произвольное количество кластеров и выбирать лучшее возможное количество кластеров - это важно, потому что в отличие от задачи классификации, которую вы изучили в Модуле 5, для нашей задачи кластеризации количество кластеров заранее неизвестно.\n",
    "\n",
    "В следующем уроке мы напишем собственную реализацию алгоритма на языке python."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "jun_ml_7_les-3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
